{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food Image Classification With a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the necessary packages\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 180\n",
    "IMG_WIDTH = 180\n",
    "train_dir = 'data/resized/train'\n",
    "test_dir = 'data/resized/test'\n",
    "dropout_rate = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75750 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                          directory=train_dir,\n",
    "                                                          shuffle=True,\n",
    "                                                          target_size=(IMG_HEIGHT,IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25250 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                          directory=test_dir,\n",
    "                                                          shuffle=True,\n",
    "                                                          target_size=(IMG_HEIGHT,IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(rate=dropout_rate),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(rate=dropout_rate),\n",
    "    Conv2D(256, 5, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(rate=dropout_rate),\n",
    "    Conv2D(512, 5, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(rate=dropout_rate),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(101,activation=None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='cosine_similarity',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 180, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 90, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 90, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 90, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 45, 45, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 45, 256)       819456    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 22, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 11, 11, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               7929984   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 101)               103525    \n",
      "=================================================================\n",
      "Total params: 12,907,365\n",
      "Trainable params: 12,901,605\n",
      "Non-trainable params: 5,760\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  1/505 [..............................] - ETA: 46:25 - loss: 0.0094 - accuracy: 0.0200\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  2/505 [..............................] - ETA: 30:54 - loss: 0.0099 - accuracy: 0.0133\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  3/505 [..............................] - ETA: 26:13 - loss: 0.0088 - accuracy: 0.0089\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  4/505 [..............................] - ETA: 23:29 - loss: 0.0054 - accuracy: 0.0067\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  5/505 [..............................] - ETA: 21:47 - loss: 0.0024 - accuracy: 0.0107\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  6/505 [..............................] - ETA: 20:39 - loss: -0.0011 - accuracy: 0.0100\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  7/505 [..............................] - ETA: 19:51 - loss: -0.0023 - accuracy: 0.0105\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  8/505 [..............................] - ETA: 19:14 - loss: -0.0042 - accuracy: 0.0117\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "  9/505 [..............................] - ETA: 18:45 - loss: -0.0053 - accuracy: 0.0126\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 10/505 [..............................] - ETA: 18:21 - loss: -0.0072 - accuracy: 0.0140\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 11/505 [..............................] - ETA: 18:01 - loss: -0.0093 - accuracy: 0.0133\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 12/505 [..............................] - ETA: 17:45 - loss: -0.0115 - accuracy: 0.0139\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 13/505 [..............................] - ETA: 17:31 - loss: -0.0127 - accuracy: 0.0138\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 14/505 [..............................] - ETA: 17:17 - loss: -0.0151 - accuracy: 0.0152\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 15/505 [..............................] - ETA: 17:06 - loss: -0.0169 - accuracy: 0.0169\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 16/505 [..............................] - ETA: 16:56 - loss: -0.0183 - accuracy: 0.0171\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 17/505 [>.............................] - ETA: 16:47 - loss: -0.0195 - accuracy: 0.0173\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 18/505 [>.............................] - ETA: 16:39 - loss: -0.0202 - accuracy: 0.0170\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 19/505 [>.............................] - ETA: 16:32 - loss: -0.0217 - accuracy: 0.0172\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 20/505 [>.............................] - ETA: 16:25 - loss: -0.0236 - accuracy: 0.0173\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 21/505 [>.............................] - ETA: 16:19 - loss: -0.0250 - accuracy: 0.0181\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 22/505 [>.............................] - ETA: 16:13 - loss: -0.0258 - accuracy: 0.0191\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 23/505 [>.............................] - ETA: 16:09 - loss: -0.0268 - accuracy: 0.0194\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 24/505 [>.............................] - ETA: 16:04 - loss: -0.0274 - accuracy: 0.0197\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 25/505 [>.............................] - ETA: 15:58 - loss: -0.0284 - accuracy: 0.0203\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 26/505 [>.............................] - ETA: 15:54 - loss: -0.0297 - accuracy: 0.0210\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 27/505 [>.............................] - ETA: 15:50 - loss: -0.0300 - accuracy: 0.0212\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 28/505 [>.............................] - ETA: 15:45 - loss: -0.0308 - accuracy: 0.0219\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 29/505 [>.............................] - ETA: 15:42 - loss: -0.0320 - accuracy: 0.0225\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 30/505 [>.............................] - ETA: 15:38 - loss: -0.0329 - accuracy: 0.0233\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 31/505 [>.............................] - ETA: 15:35 - loss: -0.0342 - accuracy: 0.0239\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 32/505 [>.............................] - ETA: 15:32 - loss: -0.0353 - accuracy: 0.0237\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 33/505 [>.............................] - ETA: 15:28 - loss: -0.0360 - accuracy: 0.0248\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 34/505 [=>............................] - ETA: 15:24 - loss: -0.0371 - accuracy: 0.0255\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 35/505 [=>............................] - ETA: 15:21 - loss: -0.0380 - accuracy: 0.0257\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 36/505 [=>............................] - ETA: 15:18 - loss: -0.0389 - accuracy: 0.0265\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 37/505 [=>............................] - ETA: 15:14 - loss: -0.0401 - accuracy: 0.0274\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 38/505 [=>............................] - ETA: 15:11 - loss: -0.0409 - accuracy: 0.0274\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 39/505 [=>............................] - ETA: 15:08 - loss: -0.0421 - accuracy: 0.0284\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 40/505 [=>............................] - ETA: 15:05 - loss: -0.0429 - accuracy: 0.0287\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 41/505 [=>............................] - ETA: 15:02 - loss: -0.0440 - accuracy: 0.0293\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 42/505 [=>............................] - ETA: 14:59 - loss: -0.0450 - accuracy: 0.0298\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 43/505 [=>............................] - ETA: 14:57 - loss: -0.0456 - accuracy: 0.0301\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 44/505 [=>............................] - ETA: 14:57 - loss: -0.0468 - accuracy: 0.0311\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 45/505 [=>............................] - ETA: 14:54 - loss: -0.0477 - accuracy: 0.0314\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 46/505 [=>............................] - ETA: 14:54 - loss: -0.0484 - accuracy: 0.0320\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 47/505 [=>............................] - ETA: 14:53 - loss: -0.0491 - accuracy: 0.0321\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 48/505 [=>............................] - ETA: 14:51 - loss: -0.0498 - accuracy: 0.0324\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 49/505 [=>............................] - ETA: 14:48 - loss: -0.0504 - accuracy: 0.0331\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 50/505 [=>............................] - ETA: 14:46 - loss: -0.0512 - accuracy: 0.0336\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 51/505 [==>...........................] - ETA: 14:47 - loss: -0.0518 - accuracy: 0.0339\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 52/505 [==>...........................] - ETA: 14:45 - loss: -0.0528 - accuracy: 0.0344\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 53/505 [==>...........................] - ETA: 14:46 - loss: -0.0538 - accuracy: 0.0346\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 54/505 [==>...........................] - ETA: 14:44 - loss: -0.0546 - accuracy: 0.0348\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 55/505 [==>...........................] - ETA: 14:45 - loss: -0.0553 - accuracy: 0.0353\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 56/505 [==>...........................] - ETA: 14:44 - loss: -0.0561 - accuracy: 0.0351\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 57/505 [==>...........................] - ETA: 14:43 - loss: -0.0566 - accuracy: 0.0352\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58/505 [==>...........................] - ETA: 14:42 - loss: -0.0574 - accuracy: 0.0352\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 59/505 [==>...........................] - ETA: 14:39 - loss: -0.0583 - accuracy: 0.0366\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 60/505 [==>...........................] - ETA: 14:38 - loss: -0.0590 - accuracy: 0.0367\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 61/505 [==>...........................] - ETA: 14:36 - loss: -0.0594 - accuracy: 0.0368\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 62/505 [==>...........................] - ETA: 14:35 - loss: -0.0598 - accuracy: 0.0368\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 63/505 [==>...........................] - ETA: 14:33 - loss: -0.0603 - accuracy: 0.0371\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 64/505 [==>...........................] - ETA: 14:31 - loss: -0.0609 - accuracy: 0.0372\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 65/505 [==>...........................] - ETA: 14:30 - loss: -0.0615 - accuracy: 0.0374\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 66/505 [==>...........................] - ETA: 14:28 - loss: -0.0622 - accuracy: 0.0375\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 67/505 [==>...........................] - ETA: 14:27 - loss: -0.0627 - accuracy: 0.0379\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 68/505 [===>..........................] - ETA: 14:24 - loss: -0.0633 - accuracy: 0.0382\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 69/505 [===>..........................] - ETA: 14:23 - loss: -0.0639 - accuracy: 0.0386\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 70/505 [===>..........................] - ETA: 14:21 - loss: -0.0644 - accuracy: 0.0390\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 71/505 [===>..........................] - ETA: 14:20 - loss: -0.0650 - accuracy: 0.0395\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 72/505 [===>..........................] - ETA: 14:18 - loss: -0.0655 - accuracy: 0.0395\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 73/505 [===>..........................] - ETA: 14:17 - loss: -0.0659 - accuracy: 0.0398\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 74/505 [===>..........................] - ETA: 14:15 - loss: -0.0666 - accuracy: 0.0403\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 75/505 [===>..........................] - ETA: 14:14 - loss: -0.0673 - accuracy: 0.0407\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 76/505 [===>..........................] - ETA: 14:11 - loss: -0.0680 - accuracy: 0.0413\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 77/505 [===>..........................] - ETA: 14:10 - loss: -0.0684 - accuracy: 0.0413\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 78/505 [===>..........................] - ETA: 14:08 - loss: -0.0690 - accuracy: 0.0419\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 79/505 [===>..........................] - ETA: 14:07 - loss: -0.0697 - accuracy: 0.0423\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 80/505 [===>..........................] - ETA: 14:06 - loss: -0.0700 - accuracy: 0.0423\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 81/505 [===>..........................] - ETA: 14:04 - loss: -0.0707 - accuracy: 0.0428\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 82/505 [===>..........................] - ETA: 14:03 - loss: -0.0711 - accuracy: 0.0433\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 83/505 [===>..........................] - ETA: 14:01 - loss: -0.0715 - accuracy: 0.0432\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      " 84/505 [===>..........................] - ETA: 13:59 - loss: -0.0720 - accuracy: 0.0434"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f791e7d148ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m           \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[0;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     if skip_input_indices is not None and 1 in skip_input_indices and _IsScalar(\n\u001b[0;32m   1168\u001b[0m         y):\n\u001b[1;32m-> 1169\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6683\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   6684\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6685\u001b[1;33m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m   6686\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6687\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=75750//batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_data_gen,\n",
    "    validation_steps=25250//batch_size,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./tmp/models'):\n",
    "    os.makedirs('./tmp/models')\n",
    "model.save('tmp/models/CNN_MODEL_V1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
